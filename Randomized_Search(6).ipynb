{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "9rLHlxV_Y8rH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "ogf-M44LYsx8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import make_scorer, f1_score, f1_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "from scipy.stats import randint\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint, uniform\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Fill the form and run it before proceeding\n",
        "language = 'Bodo' # @param [\"Assamese\",\"Bodo\", \"Bengali\", \"Sinhala\"]\n",
        "model_name = 'XGB' # @param [\"Logistic Regression\",\"Support Vector Machine\",\"Decision Tree\",\"XGB\"]\n",
        "embedding = 'count vectorizer' # @param [\"count vectorizer\",\"tfidf vectorizer\"]\n",
        "ngrams = '1-2' # @param [\"1-2\",\"1-3\"]\n",
        "train_test_split_ = True # @param {type:\"boolean\"}\n",
        "n_iter = 1 # @param {type:\"slider\", min:1, max:500, step:1}\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "euhjwLfHY7_T"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset upload"
      ],
      "metadata": {
        "id": "-jvtIivyai8z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train data upload"
      ],
      "metadata": {
        "id": "I0KT1tkZEmEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded_file = files.upload()\n",
        "uploaded_filename = list(uploaded_file.keys())[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "P_LCn9N6ZmH5",
        "outputId": "555c9539-fe5f-416e-ea51-6f501f8c78b7"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ffc08b23-b646-444f-9c70-83f20176b39a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ffc08b23-b646-444f-9c70-83f20176b39a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving train_BO_AH_HASOC2023(1).csv to train_BO_AH_HASOC2023(1) (2).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test data upload"
      ],
      "metadata": {
        "id": "odS-1mKdEo8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"please upload test data file\")\n",
        "test_file = files.upload()\n",
        "test_filename = list(test_file.keys())[0]"
      ],
      "metadata": {
        "id": "GPmRWZGPEqzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Randomized Search Class"
      ],
      "metadata": {
        "id": "EVv6Mf8ZcDPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomSearch:\n",
        "  def __init__(self,language,model_name,uploaded_filename,embedding,ngrams,train_test_split_,n_iter):\n",
        "    self.language = language\n",
        "    self.model_name = model_name\n",
        "    self.uploaded_filename = uploaded_filename\n",
        "    self.df = pd.read_csv(self.uploaded_filename)\n",
        "    self.embedding = embedding\n",
        "    self.ngrams = ngrams\n",
        "    self.vec = \"\"\n",
        "    self.train_test_split_ = train_test_split_\n",
        "    self.n_iter = n_iter\n",
        "    self.x_train = []\n",
        "    self.y_train = []\n",
        "    self.x_test = []\n",
        "    self.y_test = []\n",
        "  def username_remover(self,text):\n",
        "    text = re.sub(r'@[^ ]+',\"\", text)\n",
        "    return text\n",
        "  def clean(self,text):\n",
        "    text = re.sub(r'#\\w+', '', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    pattern = re.compile(r\"(.)\\1{2,}\")\n",
        "    words = text.split()\n",
        "    reduced_words = []\n",
        "    for word in words:\n",
        "        reduced_word = pattern.sub(r\"\\1\\1\", word)\n",
        "        reduced_words.append(reduced_word)\n",
        "    text = ' '.join(reduced_words)\n",
        "    return text\n",
        "  def fitter(self,x_train,x_test,ngrams):\n",
        "    if (ngrams==\"1-2\"):\n",
        "      ngram_range = (1,2)\n",
        "    else:\n",
        "      ngram_range = (1,3)\n",
        "    cv = CountVectorizer(ngram_range=ngram_range)\n",
        "    # cv.fit(x_train)\n",
        "    x_train_final = cv.fit_transform(x_train)\n",
        "    self.vec = cv\n",
        "    x_test_final = cv.transform(x_test)\n",
        "    print(len(cv.vocabulary_))\n",
        "    return [x_train_final,x_test_final]\n",
        "  def fitter2(self,x_train,x_test,ngrams):\n",
        "    if (ngrams==\"1-2\"):\n",
        "      ngram_range = (1,2)\n",
        "    else:\n",
        "      ngram_range = (1,3)\n",
        "    cv = TfidfVectorizer(ngram_range=ngram_range)\n",
        "    # cv.fit(x_train)\n",
        "    x_train_final = cv.fit_transform(x_train)\n",
        "    self.vec = cv\n",
        "    x_test_final = cv.transform(x_test)\n",
        "    print(len(cv.vocabulary_))\n",
        "    return [x_train_final,x_test_final]\n",
        "  def split(self):\n",
        "    # self.cleaner()\n",
        "    total = len(self.df[\"text\"].to_list())\n",
        "    self.x_train,self.x_test, self.y_train,self.y_test = train_test_split(self.df[\"text\"], self.df[\"task_1\"],stratify=self.df[\"task_1\"], test_size=2/total, random_state=42)\n",
        "    if self.embedding == \"count vectorizer\":\n",
        "      result = self.fitter(self.x_train,self.x_test,self.ngrams)\n",
        "      self.x_train = result[0]\n",
        "      self.x_test = result[1]\n",
        "    else:\n",
        "      result = self.fitter2(self.x_train,self.x_test,self.ngrams)\n",
        "      self.x_train = result[0]\n",
        "      self.x_test = result[1]\n",
        "\n",
        "\n",
        "  def cleaner(self):\n",
        "    self.df[\"text\"] = self.df[\"text\"].apply(self.username_remover)\n",
        "    self.df[\"text\"] = self.df[\"text\"].apply(self.clean)\n",
        "    self.df[\"task_1\"] = self.df[\"task_1\"].map({\"NOT\" : 0, \"HOF\":1})\n",
        "    self.df = self.df.drop_duplicates('text')\n",
        "    return self.df[\"text\"]\n",
        "  def randomsearch_decisiontree(self,n_iter):\n",
        "    X = self.x_train\n",
        "    y = self.y_train\n",
        "    param_dist = {\n",
        "        'decision_tree__criterion': ['gini', 'entropy'],\n",
        "        'decision_tree__splitter': ['best', 'random'],\n",
        "        'decision_tree__max_depth': randint(1, 100),\n",
        "        'decision_tree__min_samples_split': randint(2, 11),\n",
        "        'decision_tree__min_samples_leaf': randint(1, 11)\n",
        "    }\n",
        "    dt_classifier = DecisionTreeClassifier()\n",
        "    n_components_range = np.arange(1, X.shape[1]+1)\n",
        "    param_dist['lsa__n_components'] = n_components_range\n",
        "\n",
        "    lsa = TruncatedSVD(random_state=42)\n",
        "    pipeline = Pipeline([('lsa', lsa), ('decision_tree', dt_classifier)])\n",
        "\n",
        "    f1_scorer = make_scorer(f1_score, average='macro')\n",
        "    random_search = RandomizedSearchCV(\n",
        "        pipeline, param_distributions=param_dist, n_iter=n_iter, cv=5, random_state=42,\n",
        "        n_jobs=-1, scoring=f1_scorer\n",
        "    )\n",
        "    random_search.fit(X, y)\n",
        "    return random_search.best_params_, random_search.best_score_\n",
        "  def random_search_logistic_regression(self,n_iter):\n",
        "    X = self.x_train\n",
        "    y = self.y_train\n",
        "    param_dist = {\n",
        "        'logistic_regression__penalty': ['l1', 'l2'],\n",
        "        'logistic_regression__C': np.logspace(-4, 4, 100),\n",
        "        'logistic_regression__solver': ['liblinear', 'saga'],\n",
        "        'logistic_regression__max_iter': randint(100, 1000),\n",
        "    }\n",
        "\n",
        "    logistic_regression = LogisticRegression()\n",
        "    n_components_range = np.arange(1, X.shape[1] + 1)\n",
        "    param_dist['lsa__n_components'] = n_components_range\n",
        "\n",
        "    lsa = TruncatedSVD(random_state=42)\n",
        "    pipeline = Pipeline([('lsa', lsa), ('logistic_regression', logistic_regression)])\n",
        "\n",
        "    f1_scorer = make_scorer(f1_score, average='macro')\n",
        "    random_search = RandomizedSearchCV(\n",
        "        pipeline, param_distributions=param_dist, n_iter=n_iter, cv=5, random_state=42,\n",
        "        n_jobs=-1, scoring=f1_scorer\n",
        "    )\n",
        "    random_search.fit(X, y)\n",
        "    return random_search.best_params_, random_search.best_score_\n",
        "  def random_search_svc(self, n_iter):\n",
        "    X = self.x_train\n",
        "    y = self.y_train\n",
        "    param_dist = {\n",
        "        'svc__C': np.logspace(-4, 4, 100),\n",
        "        'svc__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "        'svc__gamma': ['scale', 'auto'] + list(np.logspace(-4, 3, 8)),\n",
        "    }\n",
        "\n",
        "    svc_classifier = SVC()\n",
        "    n_components_range = np.arange(1, X.shape[1] + 1)\n",
        "    param_dist['lsa__n_components'] = n_components_range\n",
        "\n",
        "    lsa = TruncatedSVD(random_state=42)\n",
        "    pipeline = Pipeline([('lsa', lsa), ('svc', svc_classifier)])\n",
        "\n",
        "    f1_scorer = make_scorer(f1_score, average='macro')\n",
        "    random_search = RandomizedSearchCV(\n",
        "        pipeline, param_distributions=param_dist, n_iter=n_iter, cv=5, random_state=42,\n",
        "        n_jobs=-1, scoring=f1_scorer\n",
        "    )\n",
        "    random_search.fit(X, y)\n",
        "    return random_search.best_params_, random_search.best_score_\n",
        "  def random_search_xgboost(self, n_iter):\n",
        "    X = self.x_train\n",
        "    y = self.y_train\n",
        "    param_dist = {\n",
        "        'xgb__learning_rate': np.logspace(-4, 0, 100),\n",
        "        'xgb__n_estimators': randint(50, 200),\n",
        "        'xgb__max_depth': randint(1, 20),\n",
        "        'xgb__min_child_weight': randint(1, 10),\n",
        "        'xgb__subsample': uniform(0.6, 0.4),\n",
        "        'xgb__colsample_bytree': uniform(0.6, 0.4),\n",
        "    }\n",
        "\n",
        "    xgb_classifier = XGBClassifier(random_state=42, eval_metric='mlogloss')\n",
        "    n_components_range = np.arange(1, X.shape[1] + 1)\n",
        "    param_dist['lsa__n_components'] = n_components_range\n",
        "\n",
        "    lsa = TruncatedSVD(random_state=42)\n",
        "    pipeline = Pipeline([('lsa', lsa), ('xgb', xgb_classifier)])\n",
        "\n",
        "    f1_scorer = make_scorer(f1_score, average='macro')\n",
        "    random_search = RandomizedSearchCV(\n",
        "        pipeline, param_distributions=param_dist, n_iter=n_iter, cv=5, random_state=42,\n",
        "        n_jobs=-1, scoring=f1_scorer\n",
        "    )\n",
        "    random_search.fit(X, y)\n",
        "    return random_search.best_params_, random_search.best_score_\n",
        "  def get_results(self):\n",
        "    if model_name == \"Logistic Regression\":\n",
        "      results = self.random_search_logistic_regression(self.n_iter)\n",
        "    elif model_name == \"XGB\":\n",
        "      results = self.random_search_xgboost(self.n_iter)\n",
        "    elif model_name == \"Decision Tree\":\n",
        "      results = self.randomsearch_decisiontree(self.n_iter)\n",
        "    elif model_name == \"Support Vector Machine\":\n",
        "      results = self.random_search_svc(self.n_iter)\n",
        "    return results\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MhCn39ITcC8Y"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "searcher = RandomSearch(language,model_name,uploaded_filename,embedding,ngrams,train_test_split_,n_iter)\n",
        "print(searcher.cleaner())\n",
        "searcher.split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WI4ia9CQdYPw",
        "outputId": "3006e0b1-0da7-48ef-a6b5-a524b89d56f4"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0            गोदाव खामानि मावओ बोला नो सानसे देरहा थारगोन\n",
            "1                                 निखावरि सुबुंफोरा सिखाव\n",
            "2              मा बिमा खर परिबर्थननि खोथा फैखो बेयाव मोसौ\n",
            "3                 थोद जामबा सैमा साला मा मिसेस जाखो बेलाय\n",
            "4       माखौ बकिबाय थादों नों बोरमा फानथा दम दंब्ला खा...\n",
            "                              ...                        \n",
            "1674    नोंलाय जामबा नोंबो सासे सनमान गैयै मानसिसो गिद...\n",
            "1675    एै मावजि लाब गैया दानो बनद खालामनायनि खोथा बुं...\n",
            "1676                            सिखला फुरकव रपे खलामनांगव\n",
            "1677                        सेनदेल खुबै नांगौलै सालाफोरखौ\n",
            "1678    राकेस बोरमा सिखावजोंनो थाफाहैदोलै नोंबो आदै जा...\n",
            "Name: text, Length: 1679, dtype: object\n",
            "4129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = searcher.get_results()\n",
        "print(best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj62mVPekxtd",
        "outputId": "86f4daee-75cd-4a68-f789-6b13eef79d9f"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'lsa__n_components': 861, 'xgb__colsample_bytree': 0.6733739159464655, 'xgb__learning_rate': 0.07390722033525783, 'xgb__max_depth': 7, 'xgb__min_child_weight': 3, 'xgb__n_estimators': 124, 'xgb__subsample': 0.7836995567863468}, 0.638511081263039)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeTPY8LewxJZ",
        "outputId": "cd221181-a2c5-4291-9f17-ca082dfcfcd4"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'lsa__n_components': 861,\n",
              "  'xgb__colsample_bytree': 0.6733739159464655,\n",
              "  'xgb__learning_rate': 0.07390722033525783,\n",
              "  'xgb__max_depth': 7,\n",
              "  'xgb__min_child_weight': 3,\n",
              "  'xgb__n_estimators': 124,\n",
              "  'xgb__subsample': 0.7836995567863468},\n",
              " 0.638511081263039)"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "copy_of_best_params = best_params"
      ],
      "metadata": {
        "id": "Hcqtzl_Zx46W"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "copy_of_best_params[0][\"lsa__n_components\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-cv8hD0ywkw",
        "outputId": "a6896116-2794-47e1-c7a3-dbdae363e3c0"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "861"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Tester:\n",
        "  def __init__(self,test_df,language,model_name,embedding,ngrams,model,lsa,vectorizer):\n",
        "    self.df = test_df\n",
        "    self.embedding = embedding\n",
        "    self.ngrams = ngrams\n",
        "    self.model = model\n",
        "    self.language = language\n",
        "    self.model_name = model_name\n",
        "    self.csv_filename = \"\"\n",
        "    self.lsa = lsa\n",
        "    self.vectorizer = vectorizer\n",
        "  def username_remover(self,text):\n",
        "    text = re.sub(r'@[^ ]+',\"\", text)\n",
        "    return text\n",
        "  def clean(self,text):\n",
        "    text = re.sub(r'#\\w+', '', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    pattern = re.compile(r\"(.)\\1{2,}\")\n",
        "    words = text.split()\n",
        "    reduced_words = []\n",
        "    for word in words:\n",
        "        reduced_word = pattern.sub(r\"\\1\\1\", word)\n",
        "        reduced_words.append(reduced_word)\n",
        "    text = ' '.join(reduced_words)\n",
        "    return text\n",
        "  def cleaner(self):\n",
        "    self.df[\"text\"] = self.df[\"text\"].apply(self.username_remover)\n",
        "    self.df[\"text\"] = self.df[\"text\"].apply(self.clean)\n",
        "    # self.df[\"task_1\"] = self.df[\"task_1\"].map({\"NOT\" : 0, \"HOF\":1})\n",
        "    self.df = self.df.drop_duplicates('text')\n",
        "    return self.df[\"text\"]\n",
        "  def save_predictions(self):\n",
        "    x_test = self.vectorizer.transform(self.df[\"text\"])\n",
        "    x_test_lsa = self.lsa.transform(x_test)\n",
        "    predictions = self.model.predict(x_test_lsa)\n",
        "    self.df[\"task_1\"] = list(predictions)\n",
        "    self.df = self.df.drop(\"text\", axis=1)\n",
        "    csv_filename = str(self.language)+\"_\"+str(self.model_name)+\"_\"+str(embedding)+\"_\"+str(ngrams)+\".csv\"\n",
        "    self.csv_filename = csv_filename\n",
        "    self.df.to_csv(csv_filename, index=False)\n"
      ],
      "metadata": {
        "id": "scavl7YB2tA0"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if model_name == \"Logistic Regression\":\n",
        "  lsa = TruncatedSVD(n_components=copy_of_best_params[0][\"lsa__n_components\"])\n",
        "  X_train_lsa = lsa.fit_transform(searcher.x_train)\n",
        "\n",
        "  model = LogisticRegression(\n",
        "      C=copy_of_best_params[0][\"logistic_regression__C\"],\n",
        "      max_iter=copy_of_best_params[0][\"logistic_regression__max_iter\"],\n",
        "      penalty=copy_of_best_params[0][\"logistic_regression__penalty\"],\n",
        "      solver=copy_of_best_params[0][\"logistic_regression__solver\"]\n",
        "  )\n",
        "  model.fit(X_train_lsa, searcher.y_train)\n",
        "  # print(\"please upload test data file\")\n",
        "  # test_file = files.upload()\n",
        "  # test_filename = list(test_file.keys())[0]\n",
        "  test_df = pd.read_csv(test_filename)\n",
        "  vectorizer_test = searcher.vec\n",
        "  tester = Tester(test_df,language,model_name,embedding,ngrams,model,lsa,vectorizer_test)\n",
        "  tester.cleaner()\n",
        "  tester.save_predictions()\n",
        "elif model_name == \"XGB\":\n",
        "  lsa = TruncatedSVD(n_components=copy_of_best_params[0][\"lsa__n_components\"])\n",
        "  X_train_lsa = lsa.fit_transform(searcher.x_train)\n",
        "\n",
        "  model = XGBClassifier(\n",
        "    n_estimators=copy_of_best_params[0][\"xgb__n_estimators\"],\n",
        "    max_depth=copy_of_best_params[0][\"xgb__max_depth\"],\n",
        "    learning_rate=copy_of_best_params[0][\"xgb__learning_rate\"],\n",
        "    min_child_weight = copy_of_best_params[0][\"xgb__min_child_weight\"],\n",
        "    subsample = copy_of_best_params[0][\"xgb__subsample\"],\n",
        "    colsample_bytree = copy_of_best_params[0][\"xgb__colsample_bytree\"]\n",
        "  )\n",
        "  model.fit(X_train_lsa, searcher.y_train)\n",
        "  # print(\"please upload test data file\")\n",
        "  # test_file = files.upload()\n",
        "  # test_filename = list(test_file.keys())[0]\n",
        "  test_df = pd.read_csv(test_filename)\n",
        "  vectorizer_test = searcher.vec\n",
        "  tester = Tester(test_df,language,model_name,embedding,ngrams,model,lsa,vectorizer_test)\n",
        "  tester.cleaner()\n",
        "  tester.save_predictions()\n",
        "elif model_name == \"Decision Tree\":\n",
        "  lsa = TruncatedSVD(n_components=copy_of_best_params[0][\"lsa__n_components\"])\n",
        "  X_train_lsa = lsa.fit_transform(searcher.x_train)\n",
        "\n",
        "  model = DecisionTreeClassifier(\n",
        "    criterion=copy_of_best_params[0]['decision_tree__criterion'],\n",
        "    splitter=copy_of_best_params[0]['decision_tree__splitter'],\n",
        "    max_depth=copy_of_best_params[0]['decision_tree__max_depth'],\n",
        "    min_samples_split=copy_of_best_params[0]['decision_tree__min_samples_split'],\n",
        "    min_samples_leaf=copy_of_best_params[0]['decision_tree__min_samples_leaf']\n",
        "  )\n",
        "  model.fit(X_train_lsa, searcher.y_train)\n",
        "  # print(\"please upload test data file\")\n",
        "  # test_file = files.upload()\n",
        "  # test_filename = list(test_file.keys())[0]\n",
        "  test_df = pd.read_csv(test_filename)\n",
        "  vectorizer_test = searcher.vec\n",
        "  tester = Tester(test_df,language,model_name,embedding,ngrams,model,lsa,vectorizer_test)\n",
        "  tester.cleaner()\n",
        "  tester.save_predictions()\n",
        "elif model_name == \"Support Vector Machine\":\n",
        "  lsa = TruncatedSVD(n_components=copy_of_best_params[0][\"lsa__n_components\"])\n",
        "  X_train_lsa = lsa.fit_transform(searcher.x_train)\n",
        "\n",
        "  model = SVC(\n",
        "    C=copy_of_best_params[0]['svc__C'],\n",
        "    kernel=copy_of_best_params[0]['svc__kernel'],\n",
        "    gamma=copy_of_best_params[0]['svc__gamma']\n",
        "  )\n",
        "  model.fit(X_train_lsa, searcher.y_train)\n",
        "  # print(\"please upload test data file\")\n",
        "  # test_file = files.upload()\n",
        "  # test_filename = list(test_file.keys())[0]\n",
        "  test_df = pd.read_csv(test_filename)\n",
        "  vectorizer_test = searcher.vec\n",
        "  tester = Tester(test_df,language,model_name,embedding,ngrams,model,lsa,vectorizer_test)\n",
        "  tester.cleaner()\n",
        "  tester.save_predictions()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "ujeY9wqMyD2Q",
        "outputId": "460e7515-95cf-46d9-eb7e-c0d9f8790b0d"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "please upload test data file\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8212d0b8-5d83-4c23-8f32-6a183e3c855e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8212d0b8-5d83-4c23-8f32-6a183e3c855e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving test_BO_AH_HASOC2023(1).csv to test_BO_AH_HASOC2023(1) (7).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "NVWSGTEE4BHZ",
        "outputId": "13b8c9f7-b9b4-47b9-a2ed-3a8d7de50681"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     S. No.                                               text\n",
              "0         1          BPF बानाय लांनाय लामाया 5 बोसोरानो जोरासै\n",
              "1         2  बै समाव माबेयाव हाबसोनानै दंमोन नोंलाय दाना बु...\n",
              "2         3  बे थांखिखौ मिनिग्रापोरा हारिखौ लेवारपोरबायदि थ...\n",
              "3         4               मोसौ खुगायाव एमफौ नांबाय नोंनाव सैमा\n",
              "4         5  2003आव BTC गोरोबथा जादों बेनि थाखाय बो थोजासे ...\n",
              "..      ...                                                ...\n",
              "415     416                              आं आनो खाजा होआखै मोन\n",
              "416     417  बियो आंखौ बिनि बिमा बिफा बुथारनायनि थाखाय दायन...\n",
              "417     418                   राहुलआ गावनि फोरोंगिरिखौ मान होआ\n",
              "418     419                   राकेशआ गावनि फोरोंगिरिखौ मान होआ\n",
              "419     420                    रमेशआ निखावरि मानसिखौ रायज्लाया\n",
              "\n",
              "[420 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-c5a5bf7a-1ab7-420e-b26e-32a8aab1de68\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>S. No.</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>BPF बानाय लांनाय लामाया 5 बोसोरानो जोरासै</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>बै समाव माबेयाव हाबसोनानै दंमोन नोंलाय दाना बु...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>बे थांखिखौ मिनिग्रापोरा हारिखौ लेवारपोरबायदि थ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>मोसौ खुगायाव एमफौ नांबाय नोंनाव सैमा</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2003आव BTC गोरोबथा जादों बेनि थाखाय बो थोजासे ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>416</td>\n",
              "      <td>आं आनो खाजा होआखै मोन</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>417</td>\n",
              "      <td>बियो आंखौ बिनि बिमा बिफा बुथारनायनि थाखाय दायन...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>418</td>\n",
              "      <td>राहुलआ गावनि फोरोंगिरिखौ मान होआ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>418</th>\n",
              "      <td>419</td>\n",
              "      <td>राकेशआ गावनि फोरोंगिरिखौ मान होआ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>419</th>\n",
              "      <td>420</td>\n",
              "      <td>रमेशआ निखावरि मानसिखौ रायज्लाया</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>420 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5a5bf7a-1ab7-420e-b26e-32a8aab1de68')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-27cf14d3-3e8d-4ba1-879b-e3c795dd67fe\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-27cf14d3-3e8d-4ba1-879b-e3c795dd67fe')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-27cf14d3-3e8d-4ba1-879b-e3c795dd67fe button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c5a5bf7a-1ab7-420e-b26e-32a8aab1de68 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c5a5bf7a-1ab7-420e-b26e-32a8aab1de68');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_res = pd.read_csv(tester.csv_filename)\n",
        "df_res[\"task_1\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvVfmS1_48Fk",
        "outputId": "a057bbf3-b3f6-4bd5-8154-c9b3f3bbaef2"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    304\n",
              "0    116\n",
              "Name: task_1, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EyAnafmi9wpJ"
      },
      "execution_count": 173,
      "outputs": []
    }
  ]
}